{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn_utils.models import *\n",
    "from dqn_utils.utils import define_env, train, optimize_model\n",
    "from dqn_utils.models import manDQN\n",
    "from adabyron_environment.AdaByronDEMO import AdaByronDEMO\n",
    "from dqn_utils.memory import Memory\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import random\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = AdaByronDEMO([\"aire1\", \"aire2\"], [], [\"bateria1\"])\n",
    "# action_space = env.action_space\n",
    "# actionsPerAgents = env.getAgentsActionSpace()\n",
    "\n",
    "# print(actionsPerAgents)\n",
    "# red = manDQN(2, actionsPerAgents)\n",
    "\n",
    "# tf.keras.utils.plot_model(red.model, to_file='model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.utils.plot_model(policy_network, to_file='policy_network.png', show_shapes=True, show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "Models not found, creating new ones...\n",
      "Episode: 0\n",
      "Episode: 1\n",
      "Episode: 2\n",
      "Episode: 3\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SergioI\\Python envs\\gedera_dqn_env\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 4\n",
      "Episode: 5\n",
      "Episode: 6\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Episode: 7\n",
      "Episode: 8\n",
      "Episode: 9\n",
      "Episode: 10\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Episode: 11\n",
      "Episode: 12\n",
      "Episode: 13\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Episode: 14\n",
      "Episode: 15\n",
      "Episode: 16\n",
      "Episode: 17\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Episode: 18\n",
      "Episode: 19\n",
      "Episode: 20\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Episode: 21\n",
      "Episode: 22\n",
      "Episode: 23\n",
      "Episode: 24\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Episode: 25\n",
      "Episode: 26\n",
      "Episode: 27\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Episode: 28\n",
      "Episode: 29\n",
      "Episode: 30\n",
      "Episode: 31\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Episode: 32\n",
      "Episode: 33\n",
      "Episode: 34\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Episode: 35\n",
      "Episode: 36\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\SergioI\\Proyectos\\Gedera\\DQNFlexibilityService\\main.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/SergioI/Proyectos/Gedera/DQNFlexibilityService/main.ipynb#W3sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m epsilon \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/SergioI/Proyectos/Gedera/DQNFlexibilityService/main.ipynb#W3sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m memory \u001b[39m=\u001b[39m Memory(\u001b[39m10000\u001b[39m) \u001b[39m# Memory size\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/SergioI/Proyectos/Gedera/DQNFlexibilityService/main.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m train(epsilon, MAX_STEPS, action_space, policy_network, EPS_DECAY, EPS_MIN, env, memory, BATCH_SIZE, STEP_UPDATE_MODEL, target_network, K, gamma, loss_function, optimizer, curve_pred)\n",
      "File \u001b[1;32mc:\\Users\\SergioI\\Proyectos\\Gedera\\DQNFlexibilityService\\dqn_utils\\utils.py:73\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epsilon, MAX_STEPS, action_space, policy_network, EPS_DECAY, EPS_MIN, env, memory, BATCH_SIZE, STEP_UPDATE_MODEL, target_network, K, gamma, loss_function, optimizer, generated_energy)\u001b[0m\n\u001b[0;32m     70\u001b[0m     initial_state \u001b[39m=\u001b[39m next_step\n\u001b[0;32m     72\u001b[0m \u001b[39mif\u001b[39;00m step \u001b[39m%\u001b[39m K \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(memory) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m BATCH_SIZE:\n\u001b[1;32m---> 73\u001b[0m     optimize_model(memory, BATCH_SIZE, target_network, policy_network, gamma, loss_function, optimizer, action_space)\n\u001b[0;32m     74\u001b[0m \u001b[39mif\u001b[39;00m step \u001b[39m%\u001b[39m STEP_UPDATE_MODEL \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     75\u001b[0m     target_network\u001b[39m.\u001b[39mset_weights(policy_network\u001b[39m.\u001b[39mget_weights())\n",
      "File \u001b[1;32mc:\\Users\\SergioI\\Proyectos\\Gedera\\DQNFlexibilityService\\dqn_utils\\utils.py:83\u001b[0m, in \u001b[0;36moptimize_model\u001b[1;34m(memory, BATCH_SIZE, target_network, policy_network, gamma, loss_function, optimizer, action_space)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize_model\u001b[39m(memory, BATCH_SIZE, target_network, policy_network, gamma, loss_function, optimizer, action_space):\n\u001b[0;32m     81\u001b[0m     states, actions, rewards, next_steps, dones \u001b[39m=\u001b[39m memory\u001b[39m.\u001b[39msample(BATCH_SIZE)\n\u001b[1;32m---> 83\u001b[0m     qpvalues \u001b[39m=\u001b[39m target_network\u001b[39m.\u001b[39;49mpredict(next_steps, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     85\u001b[0m     action_mask \u001b[39m=\u001b[39m action_selection(qpvalues, action_space)\n\u001b[0;32m     87\u001b[0m     qpvalues_mask \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mone_hot([action_mask], action_space[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mn, axis\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mnumpy()\n",
      "File \u001b[1;32mc:\\Users\\SergioI\\Python envs\\gedera_dqn_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\SergioI\\Python envs\\gedera_dqn_env\\Lib\\site-packages\\keras\\src\\engine\\training.py:2550\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2548\u001b[0m callbacks\u001b[39m.\u001b[39mon_predict_begin()\n\u001b[0;32m   2549\u001b[0m batch_outputs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2550\u001b[0m \u001b[39mfor\u001b[39;00m _, iterator \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39menumerate_epochs():  \u001b[39m# Single epoch.\u001b[39;00m\n\u001b[0;32m   2551\u001b[0m     \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m   2552\u001b[0m         \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n",
      "File \u001b[1;32mc:\\Users\\SergioI\\Python envs\\gedera_dqn_env\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1331\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[1;32m-> 1331\u001b[0m     data_iterator \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset)\n\u001b[0;32m   1332\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial_epoch, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epochs):\n\u001b[0;32m   1333\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SergioI\\Python envs\\gedera_dqn_env\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:506\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mor\u001b[39;00m ops\u001b[39m.\u001b[39minside_function():\n\u001b[0;32m    505\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 506\u001b[0m     \u001b[39mreturn\u001b[39;00m iterator_ops\u001b[39m.\u001b[39;49mOwnedIterator(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    507\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    508\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    509\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39miteration in eager mode or within tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\SergioI\\Python envs\\gedera_dqn_env\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:710\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    706\u001b[0m   \u001b[39mif\u001b[39;00m (components \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m element_spec \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    707\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    708\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    709\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnot be specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 710\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_iterator(dataset)\n\u001b[0;32m    712\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_next_call_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\SergioI\\Python envs\\gedera_dqn_env\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:749\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    746\u001b[0m   \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(fulltype\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39margs) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\n\u001b[0;32m    747\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_output_types)\n\u001b[0;32m    748\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator_resource\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[1;32m--> 749\u001b[0m gen_dataset_ops\u001b[39m.\u001b[39;49mmake_iterator(ds_variant, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource)\n",
      "File \u001b[1;32mc:\\Users\\SergioI\\Python envs\\gedera_dqn_env\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3451\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3449\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   3450\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3451\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   3452\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mMakeIterator\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, dataset, iterator)\n\u001b[0;32m   3453\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   3454\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Constant vars\n",
    "K = 4\n",
    "EPS_DECAY = 0.0000009\n",
    "EPS_MIN = 0.1\n",
    "BATCH_SIZE = 32\n",
    "#BATCH_SIZE = 4\n",
    "MAX_STEPS = 10000\n",
    "STEP_UPDATE_MODEL = 5000\n",
    "INPUT_SIZE = 1442\n",
    "env, policy_network, target_network, action_space  = define_env(\"test\", [\"aire1\", \"aire2\"], INPUT_SIZE=INPUT_SIZE)\n",
    "\n",
    "#model_type = \"Dense\" # Network (Dense)\n",
    "#curve_pred = [35.0, 42.5]\n",
    "#curve_pred = [35.0, 42.5, 47.5,  38.5, 33.0, 41.0, 46.0, 37.0]\n",
    "curve_pred = [random.randint(30, 50) for i in range(1440)]\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00025, clipnorm=1.0)\n",
    "loss_function = tf.keras.losses.Huber()\n",
    "seed = 42\n",
    "gamma = 0.99\n",
    "epsilon = 1\n",
    "memory = Memory(10000) # Memory size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(epsilon, MAX_STEPS, action_space, policy_network, EPS_DECAY, EPS_MIN, env, memory, BATCH_SIZE, STEP_UPDATE_MODEL, target_network, K, gamma, loss_function, optimizer, curve_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# curve_pred = [random.randint(30, 50) for i in range(1440)]\n",
    "# curve_pred2 = [random.randint(0, 112) for i in range(1440)]\n",
    "# curve_pred3 = [i for i in range(1440)]\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(90,6))\n",
    "# plt.plot(curve_pred)\n",
    "# plt.plot(curve_pred2)\n",
    "# plt.savefig(\"salidaprimerentreno.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gedera_dqn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
